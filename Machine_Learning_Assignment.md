# Practical Machine Learning Assignment
Ng Kah Earn  



# Introduction

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. Data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants are use for this project. The 6 participants were asked to perform barbell lifts correctly and incorrectly in 5 different ways classified as A, B, C, D and E and recorded as "classe" variable in the training data.

The goal of this project is to predict the manner in which the 6 participants did the exercise with the given measurement from accelerometers provided in the test data.

# Data Analysis

## Reading Data

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har.

The training data for this project is downloaded from: 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

Training data is loaded into the computer replacing blanks and "DIV/0" with NA.

```r
TrainData <- read.csv("pml-training.csv",na.strings = c("NA", "","#DIV/0!"))
```
The test data for this project is downloaded from:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

Test data is loaded into the computer replacing blanks and "DIV/0" with NA.

```r
TestData <- read.csv("pml-testing.csv",na.strings = c("NA", "","#DIV/0!"))
```

## Data Processing

We start with looking into the properties of the dataset

```r
str(TrainData)
```

```
## 'data.frame':	19622 obs. of  160 variables:
##  $ X                       : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ user_name               : Factor w/ 6 levels "adelmo","carlitos",..: 2 2 2 2 2 2 2 2 2 2 ...
##  $ raw_timestamp_part_1    : int  1323084231 1323084231 1323084231 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 ...
##  $ raw_timestamp_part_2    : int  788290 808298 820366 120339 196328 304277 368296 440390 484323 484434 ...
##  $ cvtd_timestamp          : Factor w/ 20 levels "02/12/2011 13:32",..: 9 9 9 9 9 9 9 9 9 9 ...
##  $ new_window              : Factor w/ 2 levels "no","yes": 1 1 1 1 1 1 1 1 1 1 ...
##  $ num_window              : int  11 11 11 12 12 12 12 12 12 12 ...
##  $ roll_belt               : num  1.41 1.41 1.42 1.48 1.48 1.45 1.42 1.42 1.43 1.45 ...
##  $ pitch_belt              : num  8.07 8.07 8.07 8.05 8.07 8.06 8.09 8.13 8.16 8.17 ...
##  $ yaw_belt                : num  -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 ...
##  $ total_accel_belt        : int  3 3 3 3 3 3 3 3 3 3 ...
##  $ kurtosis_roll_belt      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ kurtosis_picth_belt     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ kurtosis_yaw_belt       : logi  NA NA NA NA NA NA ...
##  $ skewness_roll_belt      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ skewness_roll_belt.1    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ skewness_yaw_belt       : logi  NA NA NA NA NA NA ...
##  $ max_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_belt          : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_belt          : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_roll_belt     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_pitch_belt    : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_yaw_belt      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_total_accel_belt    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_roll_belt        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_pitch_belt          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_pitch_belt       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_pitch_belt          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_yaw_belt         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ gyros_belt_x            : num  0 0.02 0 0.02 0.02 0.02 0.02 0.02 0.02 0.03 ...
##  $ gyros_belt_y            : num  0 0 0 0 0.02 0 0 0 0 0 ...
##  $ gyros_belt_z            : num  -0.02 -0.02 -0.02 -0.03 -0.02 -0.02 -0.02 -0.02 -0.02 0 ...
##  $ accel_belt_x            : int  -21 -22 -20 -22 -21 -21 -22 -22 -20 -21 ...
##  $ accel_belt_y            : int  4 4 5 3 2 4 3 4 2 4 ...
##  $ accel_belt_z            : int  22 22 23 21 24 21 21 21 24 22 ...
##  $ magnet_belt_x           : int  -3 -7 -2 -6 -6 0 -4 -2 1 -3 ...
##  $ magnet_belt_y           : int  599 608 600 604 600 603 599 603 602 609 ...
##  $ magnet_belt_z           : int  -313 -311 -305 -310 -302 -312 -311 -313 -312 -308 ...
##  $ roll_arm                : num  -128 -128 -128 -128 -128 -128 -128 -128 -128 -128 ...
##  $ pitch_arm               : num  22.5 22.5 22.5 22.1 22.1 22 21.9 21.8 21.7 21.6 ...
##  $ yaw_arm                 : num  -161 -161 -161 -161 -161 -161 -161 -161 -161 -161 ...
##  $ total_accel_arm         : int  34 34 34 34 34 34 34 34 34 34 ...
##  $ var_accel_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_roll_arm         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_pitch_arm        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_yaw_arm             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_yaw_arm          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_yaw_arm             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ gyros_arm_x             : num  0 0.02 0.02 0.02 0 0.02 0 0.02 0.02 0.02 ...
##  $ gyros_arm_y             : num  0 -0.02 -0.02 -0.03 -0.03 -0.03 -0.03 -0.02 -0.03 -0.03 ...
##  $ gyros_arm_z             : num  -0.02 -0.02 -0.02 0.02 0 0 0 0 -0.02 -0.02 ...
##  $ accel_arm_x             : int  -288 -290 -289 -289 -289 -289 -289 -289 -288 -288 ...
##  $ accel_arm_y             : int  109 110 110 111 111 111 111 111 109 110 ...
##  $ accel_arm_z             : int  -123 -125 -126 -123 -123 -122 -125 -124 -122 -124 ...
##  $ magnet_arm_x            : int  -368 -369 -368 -372 -374 -369 -373 -372 -369 -376 ...
##  $ magnet_arm_y            : int  337 337 344 344 337 342 336 338 341 334 ...
##  $ magnet_arm_z            : int  516 513 513 512 506 513 509 510 518 516 ...
##  $ kurtosis_roll_arm       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ kurtosis_picth_arm      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ kurtosis_yaw_arm        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ skewness_roll_arm       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ skewness_pitch_arm      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ skewness_yaw_arm        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_arm             : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_arm             : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_roll_arm      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_pitch_arm     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_yaw_arm       : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ roll_dumbbell           : num  13.1 13.1 12.9 13.4 13.4 ...
##  $ pitch_dumbbell          : num  -70.5 -70.6 -70.3 -70.4 -70.4 ...
##  $ yaw_dumbbell            : num  -84.9 -84.7 -85.1 -84.9 -84.9 ...
##  $ kurtosis_roll_dumbbell  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ kurtosis_picth_dumbbell : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ kurtosis_yaw_dumbbell   : logi  NA NA NA NA NA NA ...
##  $ skewness_roll_dumbbell  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ skewness_pitch_dumbbell : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ skewness_yaw_dumbbell   : logi  NA NA NA NA NA NA ...
##  $ max_roll_dumbbell       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_dumbbell      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_dumbbell        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_roll_dumbbell       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_dumbbell      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_dumbbell        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_roll_dumbbell : num  NA NA NA NA NA NA NA NA NA NA ...
##   [list output truncated]
```
The first step is to remove variables that are not measurements from accelerometers.

```r
TrainData1 <- TrainData[,-c(1:6)]
TestData1 <- TestData[,-c(1:6)]
```

Second step is to remove variables with more than 50% NA.


```r
is_data <- apply(!is.na(TrainData1),2,sum)>10000
training <- TrainData1[,is_data]
testing <- TestData1[,is_data]
```

# Data Modelling

We are building our model with the given training data. The training data is first partition into training set and test set. 60% of the training data is set for training of the model and 40% is set to test the model. 


```r
library(caret)
set.seed(3337)
inTrain <- createDataPartition(y= training$classe, p=0.60, list = FALSE)
training1 <- training[inTrain,]
testing1 <- training[-inTrain,]
```

## Prediction Tree Model

We will built the first model using the prediction tree algorithm. After building the model (pred_rpart); It is cross validate with testing set

```r
library(rpart)
modfit_rpart <- train(classe~., data=training1, method="rpart")
pred_rpart <- predict(modfit_rpart,testing1)
confusionMatrix(pred_rpart, testing1$classe)
```

```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2004  625  638  529  148
##          B   34  512   37  231  126
##          C  187  381  693  472  283
##          D    0    0    0    0    0
##          E    7    0    0   54  885
## 
## Overall Statistics
##                                           
##                Accuracy : 0.5218          
##                  95% CI : (0.5107, 0.5329)
##     No Information Rate : 0.2845          
##     P-Value [Acc > NIR] : < 2.2e-16       
##                                           
##                   Kappa : 0.3764          
##  Mcnemar's Test P-Value : < 2.2e-16       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.8978  0.33729  0.50658   0.0000   0.6137
## Specificity            0.6544  0.93236  0.79577   1.0000   0.9905
## Pos Pred Value         0.5081  0.54468  0.34375      NaN   0.9355
## Neg Pred Value         0.9416  0.85433  0.88422   0.8361   0.9193
## Prevalence             0.2845  0.19347  0.17436   0.1639   0.1838
## Detection Rate         0.2554  0.06526  0.08833   0.0000   0.1128
## Detection Prevalence   0.5027  0.11981  0.25695   0.0000   0.1206
## Balanced Accuracy      0.7761  0.63482  0.65117   0.5000   0.8021
```

## Random Forest Model

Next we built model using the random forest algorithm. After building the model (pred_rf); It is cross validate with testing set

```r
library(randomForest)
modfit_rf <- train(classe~.,
                   data=training1,
                   method="rf",
                   trControl=trainControl(method="cv",number=2),
                   prox=TRUE,
                   verbose=TRUE,
                   allowParallel=TRUE)
pred_rf <- predict(modfit_rf,testing1)
confusionMatrix(pred_rf, testing1$classe)
```

```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2231    3    0    0    0
##          B    0 1513    4    0    0
##          C    0    2 1364    5    0
##          D    0    0    0 1281   12
##          E    1    0    0    0 1430
## 
## Overall Statistics
##                                          
##                Accuracy : 0.9966         
##                  95% CI : (0.995, 0.9977)
##     No Information Rate : 0.2845         
##     P-Value [Acc > NIR] : < 2.2e-16      
##                                          
##                   Kappa : 0.9956         
##  Mcnemar's Test P-Value : NA             
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9996   0.9967   0.9971   0.9961   0.9917
## Specificity            0.9995   0.9994   0.9989   0.9982   0.9998
## Pos Pred Value         0.9987   0.9974   0.9949   0.9907   0.9993
## Neg Pred Value         0.9998   0.9992   0.9994   0.9992   0.9981
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2843   0.1928   0.1738   0.1633   0.1823
## Detection Prevalence   0.2847   0.1933   0.1747   0.1648   0.1824
## Balanced Accuracy      0.9995   0.9980   0.9980   0.9971   0.9958
```

## Model Comparison

Both the models are compare in terms of accuracy, time needed to process and memory required

1. The prediction tree model gives accuracy of 52.18% and error rate of 47.82%. While the random forest model gives accuracy of 99.66% and error rate of 0.34%. Random forest model gives much higher accuracy

2. The prediction tree model takes around 1 minute to run while the random forest model takes around 13 minutes to run. The prediction tree model is much faster 

3. The prediction tree model takes memory space of 11.2 Mb while the random forest model takes 1.1 Gb. The random forest model is taking a lot more memory resources. We will need a much more powerful computer to use this model.

We have selected the random forest model due to the much better accuracy.

## Prediction of Test data

Using the random forest model, we predict the activities of the 6 participants and classified as A, B, C, D and E.


```r
TestData1$problem_id <- as.factor(TestData1$problem_id)
predict(modfit_rf,TestData1)
```

```
##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E
```

From the quiz submission, we managed predict all 20 activities correctly.

# Conclusion

In this project we managed to predict all the 20 activities in the Test data using the random forest model. The random forest Model has accuracy of 99.66% and out of samples error of 0.34%.

The random forest algorithm is a better prediction algorithm as compare to the prediction tree algorithm but taking longer time to compute the results and uses a lot more memory space.

